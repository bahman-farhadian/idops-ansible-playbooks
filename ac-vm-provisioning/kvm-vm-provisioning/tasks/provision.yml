# =========================================================================
# PHASE 0: Validate and normalize input
# =========================================================================
- name: Validate instance definition list is provided
  ansible.builtin.assert:
    that:
      - kvm_instance_definitions is defined
      - kvm_instance_definitions | length > 0
    fail_msg: "Define at least one instance in vars/kvm-provisioning.yml under kvm_instance_definitions."

- name: Validate template profile map is provided
  ansible.builtin.assert:
    that:
      - kvm_template_catalog is defined
      - kvm_template_catalog is mapping
      - kvm_template_catalog | length > 0
    fail_msg: "Define at least one template profile in vars/kvm-provisioning.yml under kvm_template_catalog."

- name: Build template profile alias map by template instance name
  ansible.builtin.set_fact:
    template_profile_aliases: >-
      {{
        (template_profile_aliases | default({}))
        | combine({item.value.template_instance_name: item.key})
      }}
  loop: "{{ kvm_template_catalog | dict2items }}"
  loop_control:
    label: "{{ item.key }}"
  when:
    - item.value.template_instance_name is defined
    - item.value.template_instance_name | length > 0

- name: Build list of template instance names from catalog
  ansible.builtin.set_fact:
    template_instance_names: >-
      {{ (template_instance_names | default([])) + [item.value.template_instance_name] }}
  loop: "{{ kvm_template_catalog | dict2items }}"
  loop_control:
    label: "{{ item.key }}"
  when:
    - item.value.template_instance_name is defined
    - item.value.template_instance_name | length > 0

- name: Validate template instance names are unique
  ansible.builtin.assert:
    that:
      - template_instance_names | length == (template_instance_names | unique | length)
    fail_msg: "Each template_instance_name in kvm_template_catalog must be unique."
  when: (template_instance_names | default([])) | length > 0

- name: Validate instance profile references
  ansible.builtin.assert:
    that:
      - item.template_profile_id is defined
      - >-
        item.template_profile_id in kvm_template_catalog
        or item.template_profile_id in (template_profile_aliases | default({}))
    fail_msg: >-
      Instance {{ item.instance_name | default('unknown') }} references an undefined template_profile_id
      '{{ item.template_profile_id | default('missing') }}'. Valid profile ids:
      {{ kvm_template_catalog.keys() | list | join(', ') }}. Valid template aliases:
      {{ (template_profile_aliases | default({})).keys() | list | join(', ') }}.
  loop: "{{ kvm_instance_definitions }}"
  loop_control:
    label: "{{ item.instance_name | default('unknown') }}"

- name: Set per-instance default values
  ansible.builtin.set_fact:
    instance_defaults:
      guest_os_variant: "debian"
      guest_network_mode: "ifupdown"
      guest_network_interface: "{{ kvm_default_guest_network_interface }}"
      guest_network_prefix: "{{ kvm_default_guest_network_prefix }}"
      guest_network_gateway: "{{ kvm_default_guest_network_gateway }}"
      guest_dns_servers: "{{ kvm_default_guest_dns_servers }}"
      ssh_port: 22
      clone_disk_extension: "{{ kvm_default_clone_disk_extension }}"

- name: Build normalized instance definitions
  ansible.builtin.set_fact:
    normalized_instances: >-
      {{
        (normalized_instances | default([]))
        + [
          instance_defaults
          | combine(
              kvm_template_catalog[
                (
                  item.template_profile_id
                  if item.template_profile_id in kvm_template_catalog
                  else template_profile_aliases[item.template_profile_id]
                )
              ],
              recursive=True
            )
          | combine(item, recursive=True)
        ]
      }}
  loop: "{{ kvm_instance_definitions }}"
  loop_control:
    label: "{{ item.instance_name }}"

- name: Validate normalized instance fields
  ansible.builtin.assert:
    that:
      - item.instance_name is defined
      - item.template_instance_name is defined
      - item.template_instance_disk_files is defined
      - item.template_instance_disk_files is sequence
      - item.template_instance_disk_files is not string
      - item.template_instance_disk_files | length > 0
      - item.instance_ipv4_address is defined
      - item.vcpu_count is defined
      - item.memory_mb is defined
      - item.guest_os_variant in supported_guest_os_variants
      - item.guest_network_mode in supported_guest_network_modes
      - item.clone_disk_extension is match('^[A-Za-z0-9]+$')
      - item.instance_name != item.template_instance_name
    fail_msg: "Instance {{ item.instance_name | default('unknown') }} has invalid or missing required fields."
  loop: "{{ normalized_instances }}"
  loop_control:
    label: "{{ item.instance_name }}"

- name: Ensure workspace directory exists on hypervisor
  ansible.builtin.file:
    path: "{{ kvm_clone_workspace_path }}"
    state: directory
    mode: "0700"

- name: Validate disk pool path exists
  ansible.builtin.stat:
    path: "{{ kvm_instance_pool_path }}"
  register: instance_pool_stat
  changed_when: false

- name: Fail if disk pool path is invalid
  ansible.builtin.fail:
    msg: |
      Invalid kvm_instance_pool_path path on hypervisor: {{ kvm_instance_pool_path }}
      Update kvm_instance_pool_path in vars/kvm-provisioning.yml to a valid directory.
  when: not instance_pool_stat.stat.exists or not instance_pool_stat.stat.isdir

- name: Check runtime user access to instance pool path
  ansible.builtin.command:
    cmd: "stat {{ kvm_instance_pool_path }}"
  become: true
  become_user: "{{ kvm_libvirt_runtime_user | default('libvirt-qemu') }}"
  register: runtime_pool_access_check
  changed_when: false
  failed_when: false
  when: kvm_validate_runtime_pool_access | default(true) | bool

- name: Fail when runtime user cannot access instance pool path
  ansible.builtin.fail:
    msg: |
      Libvirt runtime user '{{ kvm_libvirt_runtime_user | default('libvirt-qemu') }}'
      cannot access kvm_instance_pool_path: {{ kvm_instance_pool_path }}
      Use a libvirt-managed path (for example /var/lib/libvirt/images) or fix path permissions/ACLs.
  when:
    - kvm_validate_runtime_pool_access | default(true) | bool
    - runtime_pool_access_check.rc != 0

- name: Build unique list of required templates
  ansible.builtin.set_fact:
    required_template_instances: "{{ normalized_instances | map(attribute='template_instance_name') | unique | list }}"

- name: Build template disk file validation list
  ansible.builtin.set_fact:
    required_template_disk_files: "{{ normalized_instances | map(attribute='template_instance_disk_files') | flatten | unique | list }}"

- name: Validate template disk files exist
  ansible.builtin.stat:
    path: "{{ item }}"
  loop: "{{ required_template_disk_files }}"
  loop_control:
    label: "{{ item }}"
  register: template_disk_file_stats
  changed_when: false

- name: Fail if any template disk files are missing
  ansible.builtin.fail:
    msg: >-
      Missing template disk files on hypervisor: {{
      template_disk_file_stats.results
      | rejectattr('stat.exists')
      | map(attribute='item')
      | join(', ')
      }}
  when: >-
    (
      template_disk_file_stats.results
      | rejectattr('stat.exists')
      | list
      | length
    ) > 0

- name: Check runtime user access to template disk files
  ansible.builtin.command:
    cmd: "stat {{ item }}"
  loop: "{{ required_template_disk_files }}"
  loop_control:
    label: "{{ item }}"
  become: true
  become_user: "{{ kvm_libvirt_runtime_user | default('libvirt-qemu') }}"
  register: runtime_template_disk_access_check
  changed_when: false
  failed_when: false
  when: kvm_validate_runtime_pool_access | default(true) | bool

- name: Fail when runtime user cannot access template disk files
  ansible.builtin.fail:
    msg: >-
      Libvirt runtime user '{{ kvm_libvirt_runtime_user | default('libvirt-qemu') }}'
      cannot access template disk file(s): {{
      runtime_template_disk_access_check.results
      | rejectattr('rc', 'eq', 0)
      | map(attribute='item')
      | join(', ')
      }}.
      Fix file and parent-directory permissions/ACLs before provisioning.
  when: >-
    (kvm_validate_runtime_pool_access | default(true) | bool)
    and (
      runtime_template_disk_access_check.results
      | rejectattr('rc', 'eq', 0)
      | list
      | length
    ) > 0

- name: Ensure template instances exist
  ansible.builtin.command:
    cmd: virsh dominfo "{{ item }}"
  loop: "{{ required_template_instances }}"
  loop_control:
    label: "{{ item }}"
  register: template_check
  changed_when: false
  failed_when: template_check.rc != 0

- name: Check template instance states
  ansible.builtin.command:
    cmd: virsh domstate "{{ item }}"
  loop: "{{ required_template_instances }}"
  loop_control:
    label: "{{ item }}"
  register: template_state_results
  changed_when: false

- name: Build list of templates currently running
  ansible.builtin.set_fact:
    templates_running: "{{ template_state_results.results | selectattr('stdout', 'equalto', 'running') | map(attribute='item') | list }}"

- name: Shut down running templates
  ansible.builtin.command:
    cmd: virsh shutdown "{{ item }}"
  loop: "{{ templates_running | default([]) }}"
  loop_control:
    label: "{{ item }}"
  register: shutdown_result
  changed_when: shutdown_result.rc == 0

- name: Wait for templates to shut down
  ansible.builtin.command:
    cmd: virsh domstate "{{ item }}"
  loop: "{{ templates_running | default([]) }}"
  loop_control:
    label: "{{ item }}"
  register: template_state_check
  until: template_state_check.stdout == "shut off"
  retries: 30
  delay: 2
  changed_when: false

- name: Check which instances already exist
  ansible.builtin.command:
    cmd: virsh dominfo "{{ item.instance_name }}"
  loop: "{{ normalized_instances }}"
  loop_control:
    label: "{{ item.instance_name }}"
  register: instance_exists_check
  failed_when: false
  changed_when: false

- name: Build list of instances to create
  ansible.builtin.set_fact:
    instances_to_create: >-
      {{ normalized_instances | zip(instance_exists_check.results)
         | selectattr('1.rc', 'ne', 0)
         | map(attribute='0')
         | list }}

- name: Build network-mode groups
  ansible.builtin.set_fact:
    instances_ifupdown: "{{ instances_to_create | selectattr('guest_network_mode', 'equalto', 'ifupdown') | list }}"
    instances_netplan: "{{ instances_to_create | selectattr('guest_network_mode', 'equalto', 'netplan') | list }}"

- name: Display instances to be created
  ansible.builtin.debug:
    msg: "Will create {{ instances_to_create | length }} instance(s): {{ instances_to_create | map(attribute='instance_name') | join(', ') }}"
  when: instances_to_create | length > 0

- name: No instances to create
  ansible.builtin.debug:
    msg: "All requested instances already exist; nothing to do."
  when: instances_to_create | length == 0

# =========================================================================
# PHASE 1: Clone instances with virt-clone
# =========================================================================
- name: "PHASE 1A: Clone instances (sequential)"
  when:
    - instances_to_create | length > 0
    - (kvm_clone_mode | default('auto')) == 'sequential'
  block:
    - name: Clone instances from profile templates (sequential)
      ansible.builtin.command:
        cmd: >-
          virt-clone
          --original "{{ item.template_instance_name }}"
          --name "{{ item.instance_name }}"
          --file "{{ kvm_instance_pool_path }}/{{ item.instance_name }}.{{ item.clone_disk_extension }}"
          --check path_in_use=off
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      register: clone_results
      changed_when: true

- name: "PHASE 1B: Clone instances (parallel)"
  when:
    - instances_to_create | length > 0
    - (kvm_clone_mode | default('auto')) == 'parallel'
  block:
    - name: Clone instances from profile templates (async)
      ansible.builtin.command:
        cmd: >-
          virt-clone
          --original "{{ item.template_instance_name }}"
          --name "{{ item.instance_name }}"
          --file "{{ kvm_instance_pool_path }}/{{ item.instance_name }}.{{ item.clone_disk_extension }}"
          --check path_in_use=off
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: "{{ kvm_clone_async_timeout_seconds | default(1800) }}"
      poll: 0
      register: clone_jobs
      changed_when: true

    - name: Wait for clone operations
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ clone_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: clone_results
      until: (clone_results.finished | default(0) | int) == 1
      retries: "{{ kvm_clone_wait_retries | default(180) }}"
      delay: "{{ kvm_clone_wait_delay_seconds | default(10) }}"
      when: item.ansible_job_id is defined

- name: "PHASE 1C: Clone instances (auto parallel + fallback)"
  when:
    - instances_to_create | length > 0
    - (kvm_clone_mode | default('auto')) == 'auto'
  block:
    - name: Clone instances from profile templates (async attempt)
      ansible.builtin.command:
        cmd: >-
          virt-clone
          --original "{{ item.template_instance_name }}"
          --name "{{ item.instance_name }}"
          --file "{{ kvm_instance_pool_path }}/{{ item.instance_name }}.{{ item.clone_disk_extension }}"
          --check path_in_use=off
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: "{{ kvm_clone_async_timeout_seconds | default(1800) }}"
      poll: 0
      register: clone_jobs
      changed_when: true

    - name: Collect clone operation results
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ clone_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: clone_results
      until: (clone_results.finished | default(0) | int) == 1
      retries: "{{ kvm_clone_wait_retries | default(180) }}"
      delay: "{{ kvm_clone_wait_delay_seconds | default(10) }}"
      when: item.ansible_job_id is defined
      failed_when: false

    - name: Build fallback and hard-failure clone lists
      ansible.builtin.set_fact:
        clone_pool_locked_instances: >-
          {{
            clone_results.results
            | selectattr('rc', 'defined')
            | selectattr('rc', 'ne', 0)
            | selectattr('stderr', 'defined')
            | selectattr('stderr', 'search', 'asynchronous jobs running')
            | map(attribute='item.item')
            | list
          }}
        clone_hard_failures: >-
          {{
            clone_results.results
            | selectattr('rc', 'defined')
            | selectattr('rc', 'ne', 0)
            | rejectattr('stderr', 'defined')
            | list
            +
            (
              clone_results.results
              | selectattr('rc', 'defined')
              | selectattr('rc', 'ne', 0)
              | selectattr('stderr', 'defined')
              | rejectattr('stderr', 'search', 'asynchronous jobs running')
              | list
            )
          }}

    - name: Fail on non-recoverable clone errors
      ansible.builtin.fail:
        msg: >-
          Clone failed for {{ clone_hard_failures | length }} instance(s) with non pool-lock errors.
          First error: {{ (clone_hard_failures | first).stderr | default((clone_hard_failures | first).msg | default('unknown error')) }}
      when: clone_hard_failures | length > 0

    - name: Retry pool-locked instances sequentially
      ansible.builtin.command:
        cmd: >-
          virt-clone
          --original "{{ item.template_instance_name }}"
          --name "{{ item.instance_name }}"
          --file "{{ kvm_instance_pool_path }}/{{ item.instance_name }}.{{ item.clone_disk_extension }}"
          --check path_in_use=off
      loop: "{{ clone_pool_locked_instances | default([]) }}"
      loop_control:
        label: "{{ item.instance_name }}"
      register: clone_fallback_results
      when: clone_pool_locked_instances | length > 0
      changed_when: true

# =========================================================================
# PHASE 2: Guest network customization by OS/network mode
# =========================================================================
- name: Generate ifupdown network files
  ansible.builtin.copy:
    dest: "{{ kvm_clone_workspace_path }}/{{ item.instance_name }}-interfaces"
    mode: "0600"
    content: |
      # Managed by Ansible (idops)
      source /etc/network/interfaces.d/*

      auto lo
      iface lo inet loopback

      allow-hotplug {{ item.guest_network_interface }}
      iface {{ item.guest_network_interface }} inet static
        address {{ item.instance_ipv4_address }}/{{ item.guest_network_prefix }}
        gateway {{ item.guest_network_gateway }}
        dns-nameservers {{ ([item.guest_dns_servers] if item.guest_dns_servers is string else item.guest_dns_servers) | join(' ') }}
  loop: "{{ instances_ifupdown }}"
  loop_control:
    label: "{{ item.instance_name }}"
  when: instances_ifupdown | length > 0

- name: Generate netplan network files
  ansible.builtin.copy:
    dest: "{{ kvm_clone_workspace_path }}/{{ item.instance_name }}-netplan.yaml"
    mode: "0600"
    content: |
      # Managed by Ansible (idops)
      network:
        version: 2
        renderer: {{ item.netplan_renderer | default('networkd') }}
        ethernets:
          {{ item.guest_network_interface }}:
            dhcp4: false
            addresses:
              - {{ item.instance_ipv4_address }}/{{ item.guest_network_prefix }}
            routes:
              - to: default
                via: {{ item.guest_network_gateway }}
            nameservers:
              addresses: {{ ([item.guest_dns_servers] if item.guest_dns_servers is string else item.guest_dns_servers) | to_json }}
  loop: "{{ instances_netplan }}"
  loop_control:
    label: "{{ item.instance_name }}"
  when: instances_netplan | length > 0

- name: Customize ifupdown guests (async)
  ansible.builtin.shell: |
    virt-customize \
      -a "{{ kvm_instance_pool_path }}/{{ item.instance_name }}.{{ item.clone_disk_extension }}" \
      --hostname "{{ item.instance_name }}" \
      --upload "{{ kvm_clone_workspace_path }}/{{ item.instance_name }}-interfaces:/etc/network/interfaces" \
      --truncate /etc/machine-id \
      --run-command "rm -f /etc/ssh/ssh_host_*" \
      --run-command "dpkg-reconfigure -f noninteractive openssh-server"
  loop: "{{ instances_ifupdown }}"
  loop_control:
    label: "{{ item.instance_name }}"
  async: 300
  poll: 0
  register: customize_ifupdown_jobs
  when: instances_ifupdown | length > 0
  changed_when: true

- name: Wait for ifupdown customization jobs
  ansible.builtin.async_status:
    jid: "{{ item.ansible_job_id }}"
  loop: "{{ customize_ifupdown_jobs.results }}"
  loop_control:
    label: "{{ item.item.instance_name }}"
  register: customize_ifupdown_results
  until: (customize_ifupdown_results.finished | default(0) | int) == 1
  retries: 60
  delay: 5
  when:
    - instances_ifupdown | length > 0
    - item.ansible_job_id is defined

- name: Customize netplan guests (async)
  ansible.builtin.shell: |
    virt-customize \
      -a "{{ kvm_instance_pool_path }}/{{ item.instance_name }}.{{ item.clone_disk_extension }}" \
      --hostname "{{ item.instance_name }}" \
      --upload "{{ kvm_clone_workspace_path }}/{{ item.instance_name }}-netplan.yaml:/etc/netplan/99-idops-static.yaml" \
      --truncate /etc/machine-id \
      --run-command "chmod 600 /etc/netplan/99-idops-static.yaml" \
      --run-command "rm -f /etc/ssh/ssh_host_*" \
      --run-command "dpkg-reconfigure -f noninteractive openssh-server"
  loop: "{{ instances_netplan }}"
  loop_control:
    label: "{{ item.instance_name }}"
  async: 300
  poll: 0
  register: customize_netplan_jobs
  when: instances_netplan | length > 0
  changed_when: true

- name: Wait for netplan customization jobs
  ansible.builtin.async_status:
    jid: "{{ item.ansible_job_id }}"
  loop: "{{ customize_netplan_jobs.results }}"
  loop_control:
    label: "{{ item.item.instance_name }}"
  register: customize_netplan_results
  until: (customize_netplan_results.finished | default(0) | int) == 1
  retries: 60
  delay: 5
  when:
    - instances_netplan | length > 0
    - item.ansible_job_id is defined

# =========================================================================
# PHASE 3: Configure resources (parallel)
# =========================================================================
- name: "PHASE 3: Configure resources"
  when: instances_to_create | length > 0
  block:
    - name: Set instance resources (async)
      ansible.builtin.shell: |
        virsh setmaxmem "{{ item.instance_name }}" "{{ item.memory_mb }}M" --config && \
        virsh setmem "{{ item.instance_name }}" "{{ item.memory_mb }}M" --config && \
        virsh setvcpus "{{ item.instance_name }}" "{{ item.vcpu_count }}" --config --maximum && \
        virsh setvcpus "{{ item.instance_name }}" "{{ item.vcpu_count }}" --config
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: 60
      poll: 0
      register: resource_jobs
      changed_when: true

    - name: Wait for resource configuration
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ resource_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: resource_results
      until: (resource_results.finished | default(0) | int) == 1
      retries: 12
      delay: 5
      when: item.ansible_job_id is defined

# =========================================================================
# PHASE 4: Start instances (parallel)
# =========================================================================
- name: "PHASE 4: Start instances"
  when: instances_to_create | length > 0
  block:
    - name: Start instances (async)
      ansible.builtin.command:
        cmd: virsh start "{{ item.instance_name }}"
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: 60
      poll: 0
      register: start_jobs
      changed_when: true

    - name: Wait for instance starts
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ start_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: start_results
      until: (start_results.finished | default(0) | int) == 1
      retries: 12
      delay: 5
      when: item.ansible_job_id is defined

# =========================================================================
# PHASE 5: Wait for SSH (parallel)
# =========================================================================
- name: "PHASE 5: Wait for SSH"
  when:
    - instances_to_create | length > 0
    - kvm_wait_for_instance_ssh | default(true) | bool
  block:
    - name: Wait for SSH on all instances (parallel)
      ansible.builtin.wait_for:
        host: "{{ item.instance_ipv4_address }}"
        port: "{{ item.ssh_port | int }}"
        delay: 5
        timeout: 180
        state: started
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }} ({{ item.instance_ipv4_address }}:{{ item.ssh_port | int }})"
      async: 180
      poll: 0
      register: ssh_wait_jobs

    - name: Confirm SSH availability
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ ssh_wait_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: ssh_results
      until: (ssh_results.finished | default(0) | int) == 1
      retries: 40
      delay: 5
      when: item.ansible_job_id is defined

# =========================================================================
# PHASE 6: Create snapshots (parallel)
# =========================================================================
- name: "PHASE 6: Create snapshots"
  when:
    - instances_to_create | length > 0
    - kvm_snapshot_enabled | default(true) | bool
  block:
    - name: Shut down instances for snapshot (async)
      ansible.builtin.command:
        cmd: virsh shutdown "{{ item.instance_name }}"
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: 60
      poll: 0
      register: shutdown_jobs
      changed_when: true

    - name: Wait for shutdown commands
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ shutdown_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: shutdown_cmd_results
      until: (shutdown_cmd_results.finished | default(0) | int) == 1
      retries: 12
      delay: 5
      when: item.ansible_job_id is defined

    - name: Wait for instances to be shut off
      ansible.builtin.command:
        cmd: virsh domstate "{{ item.instance_name }}"
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      register: instance_state
      until: instance_state.stdout == "shut off"
      retries: 30
      delay: 2
      changed_when: false

    - name: Create snapshots on all instances (async)
      ansible.builtin.command:
        cmd: >-
          virsh snapshot-create-as "{{ item.instance_name }}"
          --name "{{ kvm_snapshot_name }}"
          --description "{{ kvm_snapshot_description }}"
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: 120
      poll: 0
      register: snapshot_jobs
      changed_when: true

    - name: Wait for snapshots to complete
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ snapshot_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: snapshot_results
      until: (snapshot_results.finished | default(0) | int) == 1
      retries: 24
      delay: 5
      when: item.ansible_job_id is defined

    - name: Start instances after snapshot (async)
      ansible.builtin.command:
        cmd: virsh start "{{ item.instance_name }}"
      loop: "{{ instances_to_create }}"
      loop_control:
        label: "{{ item.instance_name }}"
      async: 60
      poll: 0
      register: final_start_jobs
      when: kvm_start_instances_after_snapshot | default(true) | bool
      changed_when: true

    - name: Wait for final instance starts
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      loop: "{{ final_start_jobs.results }}"
      loop_control:
        label: "{{ item.item.instance_name }}"
      register: final_start_results
      until: (final_start_results.finished | default(0) | int) == 1
      retries: 12
      delay: 5
      when:
        - kvm_start_instances_after_snapshot | default(true) | bool
        - item.ansible_job_id is defined

# =========================================================================
# PHASE 7: Cleanup and summary
# =========================================================================
- name: "PHASE 7: Cleanup"
  block:
    - name: Restart templates that were running before clone
      ansible.builtin.command:
        cmd: virsh start "{{ item }}"
      loop: "{{ templates_running | default([]) }}"
      loop_control:
        label: "{{ item }}"
      when: kvm_restart_template_instances_after_run | default(false) | bool
      register: restart_result
      changed_when: restart_result.rc == 0

    - name: Remove provisioning workspace when enabled
      ansible.builtin.file:
        path: "{{ kvm_clone_workspace_path }}"
        state: absent
      when: kvm_cleanup_workspace_path_after_run | default(true) | bool

- name: Summary
  ansible.builtin.debug:
    msg: |
      Instance provisioning complete.
      Created {{ instances_to_create | length }} instance(s):
      {% for instance in instances_to_create %}
        - {{ instance.instance_name }} | os={{ instance.guest_os_variant }}
          template={{ instance.template_instance_name }} | ip={{ instance.instance_ipv4_address }}
          vcpu={{ instance.vcpu_count }} | memory_mb={{ instance.memory_mb }}
      {% endfor %}
